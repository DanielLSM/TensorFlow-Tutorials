{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow to python!\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a node of a constant in tensorflow \n",
    "# tf.constant returns a tf.Tensor and defines a tf.Operation in the graph \n",
    "a = tf.constant(42,dtype=tf.int32,name='my_a',shape=(1,))\n",
    "b = tf.constant(42,dtype=tf.int32,name='my_b',shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a sum in tensorflow\n",
    "# will add a tf.Operation to the graph\n",
    "c = tf.add(a,b) \n",
    "# or c = a + b, tensorflow accepts a range of arithmetic and logical ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but what is c? c is still a tensor, tf.add() returns a tensor and\n",
    "# adds an operation to the graph\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to create a session in order to run a specific node in the\n",
    "# graph. Furthermore, we have been adding nodes to the \"default\" graph,\n",
    "# created when importing the tensorflow module, but we could've created\n",
    "# a different one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session object to run nodes in the graph\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we may run any node in the graph by using the tf.Session.run()\n",
    "# on any node we wish. \n",
    "# The nodes are the tensors and the operations the edges of the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My value of a is {}, b is {} and the sum c is {}'.format(sess.run(a),sess.run(b),sess.run(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may close a session with sess.close() which will give us an error when trying to run a node\n",
    "sess.close()\n",
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can open a different session with tf.Session() again.\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we need to dive deeper in the tensorflow structure. Tensorflow was designed to have superior computational\n",
    "# efficienty at a cost of having to define a computational graph and associated variables properly\n",
    "# Let's see how many tensors and operations we have so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the tensors currently in our default graph\n",
    "tf.contrib.graph_editor.get_tensors(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And visualize each tf.Operation added to the graph\n",
    "sess.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may notice that we have the same amount of tf.Tensors and tf.Operations.\n",
    "# The fact is, when creating anything in TensorFlow we always need a space in memory to physically have each tensor\n",
    "# And we also need a way to compute and feed each tensor onto other nodes, by defining the operations (edges)\n",
    "# Let's save our graph and visualize it on tensorboard!\n",
    "tf.train.write_graph(tf.get_default_graph(), 'folder', 'our_graph.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, we may reset the graph and all the nodes we created, since jupyter notebook is an interactive\n",
    "# python shell, remenber to reset the graph from time to time :>\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And visualize there are no tensors or operations in our graph\n",
    "tf.contrib.graph_editor.get_tensors(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the important things to be adressed. Everytime we call a tf function\n",
    "# we create a tensor (and consequently an operation), this leads to subtle memory leaks.\n",
    "for i in range(5):\n",
    "    a = tf.constant(42,dtype=tf.int32,name='my_a',shape=(1,))\n",
    "tf.contrib.graph_editor.get_tensors(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# When desiging graphs (such as neural networks) it is a good practice to define all the nodes at start\n",
    "# and running only the nodes in our code\n",
    "a = tf.constant(42,dtype=tf.int32,name='my_a',shape=(1,))\n",
    "for i in range(5):\n",
    "    print(sess.run(a)) \n",
    "tf.contrib.graph_editor.get_tensors(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy Reset\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may create tf.Variables, which will hold a variable Tensor during computations\n",
    "# Most nodes will be composed of tf.Variables.\n",
    "# There are two ways to define new variables in TensorFlow, by creating a \n",
    "# tf.Variable object or by calling tf.get_variable. \n",
    "# Calling tf.get_variable with a new name results in creating a new variable, \n",
    "# but if a variable with the same name exists it \n",
    "# will raise a ValueError exception, telling us that re-declaring \n",
    "# a variable is not allowed.\n",
    "d = tf.get_variable('my_d',[1,2,3]) #Here we already defined the shape 1-D array\n",
    "e = tf.get_variable('my_e', shape=(18,)) #Here the shape an 1-D array\n",
    "f = tf.get_variable('my_f', dtype=tf.int32, initializer=tf.constant([23, 42])) \n",
    "#Here we defined the type and the initializer which happens to be a constant tf.constant, the shape is defined\n",
    "tf.contrib.graph_editor.get_tensors(tf.get_default_graph())\n",
    "# Why are there so many tensors? the second argument is the shape. The default initializer of variables\n",
    "# is a random uniform distribution. Each Tensor of this Initializer is also created under the name of each variable\n",
    "# Notice the Tensors Assign and read, serve to feed and fetch values from the Tensor 'my_variable0':0\n",
    "# In the 'my_f' variable we only have 4 tensors, the initializer, which is a tf.constant, the \"de facto\" variable\n",
    "# 'my_f:0' and 2 other tensors to read and assing values to 'my_f:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get the session again, instead of creating a new tf.Session, this is handy on long, complex programs.\n",
    "# If there isn't any tf.Session available, it will return 'None', so we need to create another session.\n",
    "# sess = tf.Session()\n",
    "sess = tf.get_default_session()\n",
    "# Run the node f and print it\n",
    "sess.run(f)\n",
    "# Why did we got an error? the tf.initalizer is a method, and has not been run, therefore\n",
    "# there are no values to be retrieved when we run the node. We have two options: \n",
    "# 1) Either run a particular variable initializer with sess.run(f.initializer)\n",
    "# 2) Or run the tf.global_variables_initializer() which will initialize all the nodes created in the graph thus far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 42], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(f)\n",
    "# Every node (tensor) when runned, return an numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph.get_tensor_by_name('my_a:0')\n",
    "\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "\n",
    "g = tf.get_variable('my_d') #Here we use the same tensor name 'my_d' created in d to perform\n",
    "# a different computation with the same weights on another part of the program\n",
    "\n",
    "When we run a particular node,  \n",
    "\n",
    "sess.run(a)\n",
    "\n",
    "\n",
    "\n",
    "session.run(b)\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RG]",
   "language": "python",
   "name": "conda-env-RG-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
